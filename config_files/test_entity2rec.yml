experiment:
  # dataset:
  #   name: ml-100k
  #   item: # infos related to item dataset (mandatory, at least item_id)
  #     path: datasets/ml-100k/processed/item.csv
  #     extra_features: [movie_year, movie_title] # features(columns) beside item_id to be used
  #   user: # mandatory (at least user_id)
  #     path: datasets/ml-100k/processed/user.csv
  #     extra_features: [gender, occupation] # features beside user_id
  #   ratings: # mandatory (at least [user_id, item_id, rating])
  #     path: datasets/ml-100k/processed/rating.csv
  #     timestamp: True
  #   enrich:
  #     map_path: datasets/ml-100k/processed/map.csv
  #     enrich_path: datasets/ml-100k/processed/enriched.csv
  #     remove_unmatched: False
  #     properties: [subject, director, abstract]
  dataset:
    name: douban-movie
    item: # infos related to item dataset (mandatory, at least item_id)
      path: datasets/douban-movie/processed/item.csv
      extra_features: [name_EN, name_CN] # features(columns) beside item_id to be used
    user: # mandatory (at least user_id)
      path: datasets/douban-movie/processed/user.csv
      extra_features: [name]
    ratings: # mandatory (at least [user_id, item_id, rating])
      path: datasets/douban-movie/processed/rating.csv
      timestamp: False
    enrich:
      map_path: datasets/douban-movie/processed/map.csv
      enrich_path: datasets/douban-movie/processed/enriched.csv
      remove_unmatched: False
      properties: [subject, director, abstract]

  preprocess:
    # - method: filter_by_rating
    #   parameters:
    #     threshold: 20
    # - method: binarize
    #   parameters:
    #     threshold: 4
    - method: filter_kcore
      parameters:
        k: 20
        iterations: 1
        target: user # user or rating

  split:
    seed: 42
    # test:
    #   method: random_by_ratio
    #   level: global
    #   p: 0.2
    # validation:
    #   method: random_by_ratio
    #   level: global
    #   p: 0.2

    # test:
    #   method: timestamp_by_ratio
    #   level: user
    #   p: 0.1
    # validation:
    #   level: user
    #   method: timestamp_by_ratio
    #   p: 0.2

    # test:
    #   method: fixed_timestamp
    #   # type: global_level
    #   timestamp: 890000000
    # validation:
    #   method: fixed_timestamp
    #   timestamp: 880000000

    test:
      method: k_fold
      k: 5
      level: "user"

  models:
    - name: entity2rec
      config:
        save_weights: True
      parameters:
        embedding_model: deepwalk_based
        embedding_model_kwargs:
          config:
            save_weights: True
          parameters:
            walk_len: 10
            p: 1.0
            q: 1.0
            n_walks: 50
            embedding_size: 64
            epochs: 1
        workers: 6
        frac_negative_candidates: 0.2
        seed: 42

  evaluation:
    k: 5
    relevance_threshold: 0
    metrics: [MAP, nDCG]

  report:
    file: "experiment_results/e2rec_runs/ml-100k_e2rec_enriched.csv"
    execution_times:
      file: "experiment_results/e2rec_runs/ml-100k_e2rec_enriched_times.csv"
